what next:
- write preprocessing scripts: get a list of paragraphs (requires some judgement calls as to what exactly a paragraph is)
- do some exploratory unsupervised classification
- do some reading up on trade and free trade agreements
- read up the stanford nlp textbook

some issues:
- we need to write a prepro script specifically for the corpus. so we can do it __serially__ because text-preprocessing takes an incredible amount of time...... (ok this should be ok)
- how do we handle non-english texts? do we simply get rid of them i think we should
- only do one of stemming and lemmatization


what if we replaced '\n' with ' ':
+ we don't have conjoined words like 'effectivelymade'
- we will end up over-identifying paragraphs if we use a hard spacing rule (FIND A SMARTER WAY TO SPLIT BY PARAGRAPHS)
- we might end up splitting up words (write a script for checking adjacent words (big yikes...). if is a word, join them together [what about words that mean something both together and separately? this should be relatively rare])


scrape_:
- ONLY scrape
- do not do any treatment, even for whitespace markers like '\n'

cleaner:
- does administrative cleaning, like whitespacing, paragraph splitting, etc.

preProcessor:
- does nlp prepro



jsepa